{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch import optim\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=(r'/Users/namanparuthi/Desktop/Rock Paper Scissors SXSW-3/train',\n",
    "               r'/Users/namanparuthi/Desktop/Rock Paper Scissors SXSW-3/train/_annotations.csv',\n",
    "                             \n",
    "                             \n",
    "                             )\n",
    "\n",
    "test_dataset=(r'/Users/namanparuthi/Desktop/Rock Paper Scissors SXSW-3/test',\n",
    "              r'/Users/namanparuthi/Desktop/Rock Paper Scissors SXSW-3/test/_annotations.csv',\n",
    "                             \n",
    "                         \n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=10,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the object detecton model(R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_object_detection_model(num_classes):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the classification CNN(custom cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ClassificationCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the detection and classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, num_classes_detection, num_classes_classification):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.object_detection_model = create_object_detection_model(num_classes_detection)\n",
    "        self.classification_model = CombinedModel(num_classes_classification)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Object Detection\n",
    "        detection_output = self.object_detection_model(images)\n",
    "        boxes = detection_output[0]['boxes']\n",
    "        # Crop and classify detected objects\n",
    "        object_images = [F.crop(images[i], int(box[1]), int(box[0]), int(box[3]) - int(box[1]), int(box[2]) - int(box[0])) for i, box in enumerate(boxes)]\n",
    "        object_images = torch.stack(object_images)\n",
    "        classification_output = self.classification_model(object_images)\n",
    "        return detection_output, classification_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs,optimizer,model,loss_fn,train_loader):\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        loss_train=0.0\n",
    "        loss_cmu=0\n",
    "        for image,label in train_loader:\n",
    "            outputs=model(image)\n",
    "            loss=loss_fn(outputs,label)\n",
    "            loss_train=0\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            print(loss_train)\n",
    "            loss_cmu+=loss_train\n",
    "\n",
    "        if epoch==1 or epoch%10==0: \n",
    "            print(f'{datetime.datetime.now()} Epoch {epoch}, train loss={loss_cmu}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CombinedModel(3,3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CombinedModel(3,3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop2(n_epochs,optimizer,model,loss_fn,train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "    # Train\n",
    "        for batch_idx, data, target in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            data=data\n",
    "            target=target\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CombinedModel(3,3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
